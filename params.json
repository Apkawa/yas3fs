{"name":"YAS3FS","tagline":"Yet Another S3-backed File System","body":"### Yet Another S3-backed File System: yas3fs\r\n\r\nYAS3FS (Yet Another S3-backed File System) is a [Filesystem in Userspace (FUSE)](http://fuse.sourceforge.net)\r\ninterface to [Amazon S3](http://aws.amazon.com/s3/).\r\nIt was inspired by [s3fs](http://code.google.com/p/s3fs/) but rewritten from scratch to implement\r\na distributed cache synchronized by [Amazon SNS](http://aws.amazon.com/sns/) notifications.\r\nA web console is provided to easily monitor the nodes of a cluster.\r\n\r\n**If you use YAS3FS please share your experience on the [wiki](https://github.com/danilop/yas3fs/wiki), thanks!**\r\n\r\n* It allows to mount an S3 bucket (or a part of it, if you specify a path) as a local folder.\r\n* It works on Linux and Mac OS X.\r\n* For maximum speed all data read from S3 is cached locally on the node, in memory or on disk, depending of the file size.\r\n* Parallel multi-part downloads are used if there are reads in the middle of the file (e.g. for streaming).\r\n* Parallel multi-part uploads are used for files larger than a specified size.\r\n* With buffering enabled (the default) files can be accessed during the download from S3 (e.g. for streaming).\r\n* It can be used on more than one node to create a \"shared\" file system (i.e. a yas3fs \"cluster\").\r\n* [SNS](http://aws.amazon.com/sns/) notifications are used to update other nodes in the cluster that something has changed on S3 and they need to invalidate their cache.\r\n* Notifications can be listened using HTTP or [SQS](http://aws.amazon.com/sqs/) endpoints.\r\n* If the cache grows to its maximum size, the less recently accessed files are removed.\r\n* AWS credentials can be passed using AWS\\_ACCESS\\_KEY\\_ID and AWS\\_SECRET\\_ACCESS\\_KEY environment variables.\r\n* In an [EC2](http://aws.amazon.com/ec2/) instance a [IAM](http://aws.amazon.com/iam/) role can be used to give access to S3/SNS/SQS resources.\r\n* It is written in Python (2.6) using [boto](https://github.com/boto/boto) and [fusepy](https://github.com/terencehonles/fusepy).\r\n\r\nThis is a personal project. No relation whatsoever exists between this project and my employer.\r\n\r\n### License\r\n\r\nCopyright (c) 2012-2013 Danilo Poccia, http://blog.danilopoccia.net\r\n\r\nThis code is licensed under the The MIT License (MIT). Please see the LICENSE file that accompanies this project for the terms of use.\r\n\r\n### Introduction\r\n\r\nThis is the logical architecture of yas3fs:\r\n\r\n![yas3fs Logical Architecture](http://blog.danilopoccia.net/wp-content/uploads/sites/2/2012/11/yas3fs.png.scaled500.png)\r\n\r\nI strongly suggest to start yas3fs for the first time with the `-df` (debug + foreground) options, to see if there is any error.\r\nWhen everything works it can be interrupted (with `^C`) and restarted to run in background\r\n(it's the default with no `-f` options).\r\n\r\nTo mount an S3 bucket without using SNS (i.e. for a single node):\r\n\r\n    yas3fs /path/to/mount --url s3://bucket/path \r\n\r\nTo persist file system metadata such as attr/xattr yas3fs is using S3 User Metadata.\r\nTo mount an S3 bucket without actually writing metadata in it,\r\ne.g. because it is a bucket you mainly use as a repository and not as a file system,\r\nyou can use the `--no-metadata` option.\r\n\r\nTo mount an S3 bucket using SNS and listening to an SQS endpoint:\r\n\r\n    yas3fs /path/to/mount --url s3://bucket/path --topic TOPIC-ARN --new-queue\r\n\r\nTo mount an S3 bucket using SNS and listening to an HTTP endpoint (on EC2):\r\n\r\n    yas3fs /path/to/mount --url s3://bucket/path --topic TOPIC-ARN --ec2-hostname --port N\r\n\r\nOn EC2 the security group must allow inbound traffic from SNS on the selected port.\r\n\r\nOn EC2 the command line doesn't need any information on the actual server and can easily be used\r\nwithin an [Auto Scaling](http://aws.amazon.com/autoscaling/) group.\r\n\r\n### Quick Installation\r\n\r\nIf you want to do a quick test here's the installation procedure depending on the OS flavor (Linux or Mac):\r\n\r\n* Create an S3 bucket in the AWS region you prefer.\r\n* You don't need to create anything in the bucket as the initial path (if any) is created by the tool on the first mount.\r\n* If you want to use an existing S3 bucket you can use the `--no-metadata` option to not use user metadata to persist file system attr/xattr.\r\n* Create an SNS topic in the same region as the S3 bucket and write down the full topic ARN (you need it to run the tool if more than one client is connected to the same bucket/path).\r\n* Create a IAM Role that gives access to the S3 and SNS/SQS resources you need or pass the AWS credentials to the tool using environment variables (see `-h`).\r\n* I used the `eu-west-1` region in my sample, but you can replace that with any region you want. If no region is specified it defaults to `us-east-1`.\r\n\r\n**On EC2 with Amazon Linux**\r\n\r\n    sudo yum -y install fuse fuse-libs git\r\n    sudo easy_install pip\r\n    sudo pip install -U boto fusepy\r\n    sudo sed -i'' 's/^# *user_allow_other/user_allow_other/' /etc/fuse.conf # uncomment user_allow_other\r\n    cd /opt # To install yas3fs under /opt/yas3fs\r\n    sudo git clone git://github.com/danilop/yas3fs.git\r\n    cd yas3fs\r\n    ./yas3fs -h # See the usage\r\n    mkdir LOCAL-PATH\r\n    # For single host mount\r\n    ./yas3fs LOCAL-PATH --url s3://BUCKET/PATH\r\n    # For multiple hosts mount\r\n    ./yas3fs LOCAL-PATH --url s3://BUCKET/PATH --topic TOPIC-ARN --new-queue\r\n\r\n**On EC2 with Ubuntu systems**\r\n\r\n    sudo apt-get install fuse-utils libfuse2 python-pip git\r\n    sudo pip install -U boto fusepy\r\n    sudo sed -i'' 's/^# *user_allow_other/user_allow_other/' /etc/fuse.conf # uncomment user_allow_other\r\n    cd /opt # To install yas3fs under /opt/yas3fs\r\n    sudo git clone git://github.com/danilop/yas3fs.git\r\n    cd yas3fs\r\n    ./yas3fs -h # See the usage\r\n    sudo chmod a+r /etc/fuse.conf # make it readable by anybody, it is not the default on Ubuntu\r\n    mkdir LOCAL-PATH\r\n    # For single host mount\r\n    ./yas3fs LOCAL-PATH --url s3://BUCKET/PATH\r\n    # For multiple hosts mount\r\n    ./yas3fs LOCAL-PATH --url s3://BUCKET/PATH --topic TOPIC-ARN --new-queue\r\n\r\n**On a Mac with OS X**\r\n\r\nInstall FUSE for OS X from <http://osxfuse.github.com>\r\n\r\n    sudo easy_install boto\r\n    sudo easy_install fusepy\r\n    cd /opt # To install yas3fs under /opt/yas3fs\r\n    sudo git clone git://github.com/danilop/yas3fs.git\r\n    cd yas3fs\r\n    ./yas3fs -h # See the usage\r\n    mkdir LOCAL-PATH\r\n    # For single host mount\r\n    ./yas3fs LOCAL-PATH --url s3://BUCKET/PATH\r\n    # For multiple hosts mount\r\n    ./yas3fs LOCAL-PATH --url s3://BUCKET/PATH --topic TOPIC-ARN --new-queue\r\n\r\nTo listen to SNS HTTP notifications (I usually suggest to use SQS instead)\r\nyou need to install the Python [M2Crypto](http://chandlerproject.org/Projects/MeTooCrypto) module,\r\ndownload the most suitable \"egg\" from\r\n<http://chandlerproject.org/Projects/MeTooCrypto#Downloads>.\r\n\r\n    sudo easy_install M2Crypto-*.egg\r\n\r\nIf something does not work as expected you can use the `-df` options to run in foreground in debug mode.\r\n\r\n**Unmount**\r\n\r\nTo unmount the file system on Linux:\r\n\r\n    fusermount -u LOCAL-PATH\r\n\r\nTo unmount the file system on a Mac you can use `umount`.\r\n\r\n### Full Usage\r\n\r\n    yas3fs -h\r\n\r\n    Usage: yas3fs <mountpoint> [options]\r\n\r\n    YAS3FS (Yet Another S3-backed File System) is a Filesystem in Userspace (FUSE) interface to Amazon S3.\r\n\r\n    It allows to mount an S3 bucket (or a part of it, if you specify a path) as a local folder.\r\n    It works on Linux and Mac OS X.\r\n    For maximum speed all data read from S3 is cached locally on the node, in memory or on disk, depending of the file size.\r\n    Parallel multi-part downloads are used if there are reads in the middle of the file (e.g. for streaming).\r\n    Parallel multi-part uploads are used for files larger than a specified size.\r\n    With buffering enabled (the default) files can be accessed during the download from S3 (e.g. for streaming).\r\n    It can be used on more than one node to create a \"shared\" file system (i.e. a yas3fs \"cluster\").\r\n    SNS notifications are used to update other nodes in the cluster that something has changed on S3 and they need to invalidate their cache.\r\n    Notifications can be listened using HTTP or SQS endpoints.\r\n    If the cache grows to its maximum size, the less recently accessed files are removed.\r\n    AWS credentials can be passed using AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables.\r\n    In an EC2 instance a IAM role can be used to give access to S3/SNS/SQS resources.\r\n\r\n    Options:\r\n      -h, --help           show this help message and exit\r\n      --url=URL            the S3 path to mount in s3://BUCKET/PATH format, PATH\r\n                           can be empty, can contain subfolders and is created on\r\n                           first mount if not found in the BUCKET\r\n      --region=REGION      AWS region to use for SNS/SQS (default is us-east-1)\r\n      --topic=ARN          SNS topic ARN\r\n      --hostname=HOST      hostname to listen to SNS HTTP notifications\r\n      --ec2-hostname       get public hostname from EC2 instance metadata\r\n                           (overrides '--hostname')\r\n      --port=N             TCP port to listen to SNS HTTP notifications\r\n      --queue=NAME         SQS queue name, a new queue is created if it doesn't\r\n                           exist\r\n      --new-queue          create a new SQS queue that is deleted on unmount\r\n                           (overrides '--queue', queue name is BUCKET-PATH-ID with\r\n                           alphanumeric characters only)\r\n      --queue-wait=N       SQS queue wait time in seconds (using long polling, 0\r\n                           to disable, default is 20 seconds)\r\n      --queue-polling=N    SQS queue polling interval in seconds (default is 0\r\n                           seconds)\r\n      --cache-entries=N    max number of entries to cache (default is 1000000\r\n                           entries)\r\n      --cache-mem-size=N   max size of the memory cache in MB (default is 1024 MB)\r\n      --cache-disk-size=N  max size of the disk cache in MB (default is 10240 MB)\r\n      --cache-path=PATH    local path to use for disk cache (default is\r\n                           '/tmp/yas3fs/BUCKET/PATH')\r\n      --cache-on-disk=N    use disk (instead of memory) cache for files greater\r\n                           than the given size in MB (default is 100 MB)\r\n      --cache-check=N      interval between cache memory checks in seconds\r\n                           (default is 10 seconds)\r\n      --download-num=N     number of parallel downloads (default is 4)\r\n      --prefetch-num=N     number of parallel prefetching downloads (default is 1)\r\n      --buffer-size=N      download buffer size in KB (0 to disable buffering,\r\n                           default is 10240 KB)\r\n      --buffer-prefetch=N  number of buffers to prefetch (default is 0)\r\n      --no-metadata        don't write user metadata on S3 to persist file system\r\n                           attr/xattr\r\n      --prefetch           start downloading file content as soon as the file is\r\n                           discovered\r\n      --mp-size=N          size of parts to use for multipart upload in KB\r\n                           (default value is 10240 KB, the minimum allowed is 5120\r\n                           KB)\r\n      --mp-num=N           max number of parallel multipart uploads per file (0 to\r\n                           disable multipart upload, default is 4)\r\n      --mp-retries=N       max number of retries in uploading a part (default is 3)\r\n      --id=ID              a unique ID identifying this node in a cluster\r\n      --mkdir              create mountpoint if not found (create intermediate\r\n                           directories as required)\r\n      --uid=N              default UID (default is current UID)\r\n      --gid=N              default GID (default is current GID)\r\n      --umask=MASK         default umask (default is current umask)\r\n      -l FILE, --log=FILE  the filename to use for logs\r\n      -f, --foreground     run in foreground\r\n      -d, --debug          print debug information (implies '-f')\r\n\r\n### Web console\r\n\r\nA web console to easy monitor the nodes of a cluster (i.e. that are listening to the same SNS topic)\r\nis in the \"yas3fs-console/\" subdirectory.\r\n\r\n* AWS credentials can be passed using AWS\\_ACCESS\\_KEY\\_ID and AWS\\_SECRET\\_ACCESS\\_KEY environment variables.\r\n* The AWS_REGION environment variable must point to a valid AWS reagion (e.g. eu-west-1)\r\n* In an [EC2](http://aws.amazon.com/ec2/) instance a [IAM](http://aws.amazon.com/iam/) role can be used to give access to S3/SNS/SQS resources.\r\n\r\nIt is based on [Node.js](http://nodejs.org) and once \"node\" is [installed](http://nodejs.org/download/) you can run it with:\r\n\r\n    git clone git://github.com/danilop/yas3fs.git\r\n    cd yas3fs/yas3fs-console\r\n    npm install\r\n    node server.js\r\n\r\nIt is using the 3000 port by default (e.g. \"http://localhost:3000\"), but you can change it using the PORT environment variable, e.g.:\r\n\r\n    export PORT=8080\r\n    node yas3fs-console/server.js\r\n\r\nHere’s a sample screenshot of the web interface:\r\n\r\n![YAS3FS Console screenshot](http://blog.danilopoccia.net/wp-content/uploads/sites/2/2013/06/yas3fs-console.png)\r\n\r\nThe list of nodes and the attributes are updated dynamically depending on the configuration parameters.\r\n\r\nIn the future I’d like to add management capabilities as well into the console, such as “cache reset on a node”, or alarms, such as “disk cache is running out of space”.\r\n\r\n### Notification Syntax & Use\r\n\r\nYou can use the SNS topic for other purposes than keeping the cache of the nodes in sync.\r\nThose are some sample use cases:\r\n\r\n* You can listen to the SNS topic to be updated on changes on S3 (if done through yas3fs).\r\n* You can publish on the SNS topic to manage the overall \"cluster\" of yas3fs nodes.\r\n\r\nThe SNS notification syntax is based on [JSON (JavaScript Object Notation)](http://www.json.org):\r\n\r\n    [ \"node_id\", \"action\", ... ]\r\n\r\nThe following `action`(s) are currently implemented:\r\n\r\n* `mkdir` (new directory): `[ \"node_id\", \"mkdir\", \"path\" ]`\r\n* `rmdir` (remove directory): `[ \"node_id\", \"rmdir\", \"path\" ]`\r\n* `mknod` (new empty file): `[ \"node_id\", \"mknod\", \"path\" ]`\r\n* `unlink` (remove file): `[ \"node_id\", \"unlink\", \"path\" ]`\r\n* `symlink` (new symbolic link): `[ \"node_id\", \"symlink\", \"path\" ]`\r\n* `rename` (rename file or directory): `[ \"node_id\", \"rename\", \"old_path\", \"new_path\" ]`\r\n* `flush` (updated file): `[ \"node_id\", \"flush\", \"path\", \"new_md5\" ]` (`path` and `new_md5` are optional)\r\n* `md` (updated metadata, e.g. attr/xattr): `[ \"node_id\", \"md\", \"path\", \"metadata_name\" ]`\r\n* `reset` (reset cache): `[ \"node_id\", \"reset\" ]`\r\n* `cache` (change cache config): `[ \"node_id\", \"cache\" , \"entries\" or \"mem\" or \"disk\", new_value ]`\r\n* `buffer` (change buffer config): `[ \"node_id\", \"buffer\", \"size\" or \"prefetch\", new_value ]`\r\n* `prefetch` (change prefetch config): `[ \"node_id\", \"prefetch\", \"on\" or \"off\" ]`\r\n* `url` (change S3 url): `[ \"node_id\", \"url\", \"s3://BUCKET/PATH\" ]`\r\n\r\nEvery node will listen to notifications coming from a `node_id` different from its own id.\r\nAs an example, if you want to reset the cache of all the nodes in a yas3fs cluster,\r\nyou can send the following notification to the SNS topic (assuming there is no node with id equal to `all`):\r\n\r\n    [ \"all\", \"reset\" ]\r\n\r\nTo send the notification you can use the SNS web console or any command line tool that supports SNS, such as [AWS CLI](http://aws.amazon.com/cli/).\r\n\r\nIn the same way, if you uploaded a new file (or updated an old one) directly on S3 \r\nyou can invalidate the caches of all the nodes in the yas3fs cluster for that `path` sending this SNS notification:\r\n\r\n    [ \"all\", \"flush\", \"path\" ]\r\n\r\nThe `path` is the relative path of the file system (`/` corresponding to the mount point)\r\nand doesn't include any S3 path (i.e. prefix) as given in the `--url` option.\r\n\r\nTo change the size of the memory cache on all nodes, e.g. to bring it from 1GB (the current default) to 10GB,\r\nyou can publish (the size is in MB as in the corresponding command line option):\r\n\r\n    [ \"all\", \"cache\", \"mem\", 10240 ]\r\n\r\nTo change the size of the disk cache on all nodes, e.g. to bring it from 10GB (the current default) to 1TB,\r\nyou can publish (the size is in MB as in the corresponding command line option):\r\n\r\n    [ \"all\", \"cache\", \"disk\", 1048576 ]\r\n\r\nTo change the buffer size used to download the content (and make it available for reads) from the default of 10MB (optimized for a full download speed) to 256KB (optimized for a streaming service) you can use (the size is in KB, as in the corresponding command line option):\r\n\r\n    [ \"all\", \"buffer\", \"size\", 256 ]\r\n\r\nTo change buffer prefetch from the default of 0 to 1 (optimized for sequential access) you can publish:\r\n\r\n    [ \"all\", \"buffer\", \"prefetch\", 1 ]\r\n\r\nSimilarly, to activate download prefetch of all files on all nodes you can use:\r\n\r\n    [ \"all\", \"prefetch\", \"on\" ]\r\n\r\nTo change the multipart upload size to 100MB:\r\n\r\n    [ \"all\", \"multipart\", \"size\", 102400 ]\r\n\r\nTo change the maximum number of parallel threads to use for multipart uploads to 16:\r\n\r\n    [ \"all\", \"multipart\", \"num\", 16 ]\r\n\r\nTo change the maximum number of retries for multipart uploads to 10:\r\n\r\n    [ \"all\", \"multipart\", \"retries\", 10 ]\r\n\r\nYou can even change dinamically the mounted S3 URL (i.e. the bucket and/or the path prefix):\r\n\r\n    [ \"all\", \"url\", \"s3://BUCKET/PATH\" ]\r\n\r\nTo check the status of all the yas3fs instances listening to a topic you can use:\r\n\r\n    [ \"all\", \"ping\" ]\r\n\r\nTo the previous message all yas3fs instances will answer publishing a message on the topic with this content:\r\n\r\n    [ \"id\", \"status\", hostname, number of entries in cache, cache memory size,\r\n      cache disk size, download queue length, prefetch queue length ]\r\n\r\nHappy File Sharing!\r\n\r\n\r\n[![Bitdeli Badge](https://d2weczhvl823v0.cloudfront.net/danilop/yas3fs/trend.png)](https://bitdeli.com/free \"Bitdeli Badge\")\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}